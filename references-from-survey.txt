


[Wang et al., 2022] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain
of thought reasoning in language models. arXiv preprint
arXiv:2203.11171, 2022.
[Wang et al., 2024] Zilong Wang, Hao Zhang, Chun-Liang
Li, Julian Martin Eisenschlos, Vincent Perot, Zifeng Wang,
Lesly Miculicich, Yasuhisa Fujii, Jingbo Shang, Chen-Yu
Lee, and Tomas Pfister. Chain-of-table: Evolving tables in
the reasoning chain for table understanding, 2024.
[Wei et al., 2022] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny
Zhou, et al. Chain-of-thought prompting elicits reasoning
in large language models. Advances in Neural Information
Processing Systems, 35:24824–24837, 2022.
[Weston and Sukhbaatar, 2023] Jason Weston and Sainbayar
Sukhbaatar. System 2 attention (is something you might
need too). arXiv preprint arXiv:2311.11829, 2023.
[Wu et al., 2023] Chenfei Wu, Shengming Yin, Weizhen Qi,
Xiaodong Wang, Zecheng Tang, and Nan Duan. Visual
chatgpt: Talking, drawing and editing with visual foundation models, 2023.
[Yang et al., 2023] Chengrun Yang, Xuezhi Wang, Yifeng
Lu, Hanxiao Liu, Quoc V Le, Denny Zhou, and Xinyun
Chen. Large language models as optimizers. arXiv preprint
arXiv:2309.03409, 2023.
[Yao et al., 2022] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan
Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models.
arXiv preprint arXiv:2210.03629, 2022.
[Yao et al., 2023a] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak
Shafran, Thomas L Griffiths, Yuan Cao, and Karthik
Narasimhan. Tree of thoughts: Deliberate problem
solving with large language models. arXiv preprint
arXiv:2305.10601, 2023.
[Yao et al., 2023b] Yao Yao, Zuchao Li, and Hai Zhao. Beyond chain-of-thought, effective graph-of-thought reasoning in large language models. arXiv preprint
arXiv:2305.16582, 2023.
[Yu et al., 2023] Wenhao Yu, Hongming Zhang, Xiaoman
Pan, Kaixin Ma, Hongwei Wang, and Dong Yu. Chainof-note: Enhancing robustness in retrieval-augmented language models, 2023.
[Zhang et al., 2022] Zhuosheng Zhang, Aston Zhang, Mu Li,
and Alex Smola. Automatic chain of thought prompting in
large language models. arXiv preprint arXiv:2210.03493,
2022.
[Zhao et al., 2023] Xufeng Zhao, Mengdi Li, Wenhao Lu,
Cornelius Weber, Jae Hee Lee, Kun Chu, and Stefan
Wermter. Enhancing zero-shot chain-of-thought reasoning in large language models through logic, 2023.
[Zheng et al., 2023] Huaixiu Steven Zheng, Swaroop Mishra,
Xinyun Chen, Heng-Tze Cheng, Ed H Chi, Quoc V Le,
and Denny Zhou. Take a step back: evoking reasoning
via abstraction in large language models. arXiv preprint
arXiv:2310.06117, 2023.
[Zhou et al., 2022] Yongchao Zhou, Andrei Ioan Muresanu,
Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and
Jimmy Ba. Large language models are human-level prompt
engineers. arXiv preprint arXiv:2211.01910, 2022.
[Zhou et al., 2023] Yucheng Zhou, Xiubo Geng, Tao Shen,
Chongyang Tao, Guodong Long, Jian-Guang Lou, and Jianbing Shen. Thread of thought unraveling chaotic contexts.
arXiv preprint arXiv:2311.08734, 2023.

References
[Bahng et al., 2022] Hyojin Bahng, Ali Jahanian, Swami
Sankaranarayanan, and Phillip Isola. Exploring visual
prompts for adapting large-scale models. arXiv preprint
arXiv:2203.17274, 2022.
[Brown et al., 2020] Tom B. Brown, Benjamin Mann, Nick
Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen
Krueger, Tom Henighan, Rewon Child, Aditya Ramesh,
Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott
Gray, Benjamin Chess, Jack Clark, Christopher Berner,
Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario
Amodei. Language models are few-shot learners, 2020.
[Chen et al., 2022] Wenhu Chen, Xueguang Ma, Xinyi Wang,
and William W Cohen. Program of thoughts prompting:
Disentangling computation from reasoning for numerical
reasoning tasks. arXiv preprint arXiv:2211.12588, 2022.
[Chen et al., 2023] Banghao Chen, Zhaofeng Zhang, Nicolas
Langrené, and Shengxin Zhu. Unleashing the potential of
prompt engineering in large language models: a comprehensive review. arXiv preprint arXiv:2310.14735, 2023.
[Chia et al., 2023] Yew Ken Chia, Guizhen Chen, Luu Anh
Tuan, Soujanya Poria, and Lidong Bing. Contrastive chainof-thought prompting. arXiv preprint arXiv:2311.09277,
2023.
[Deng et al., 2023] Yihe Deng, Weitong Zhang, Zixiang
Chen, and Quanquan Gu. Rephrase and respond: Let large
language models ask better questions for themselves. arXiv
preprint arXiv:2311.04205, 2023.
[Dhuliawala et al., 2023] Shehzaad Dhuliawala, Mojtaba
Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston. Chain-of-verification reduces
hallucination in large language models. arXiv preprint
arXiv:2309.11495, 2023.
[Diao et al., 2023] Shizhe Diao, Pengcheng Wang, Yong
Lin, and Tong Zhang. Active prompting with chainof-thought for large language models. arXiv preprint
arXiv:2302.12246, 2023.
[Hu et al., 2023] Hanxu Hu, Hongyuan Lu, Huajian Zhang,
Yun-Ze Song, Wai Lam, and Yue Zhang. Chain-of-symbol
prompting elicits planning in large langauge models, 2023.
[Lewis et al., 2020] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman
Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
Rocktäschel, et al. Retrieval-augmented generation for
knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33:9459–9474, 2020.
[Li et al., 2023a] Cheng Li, Jindong Wang, Yixuan Zhang,
Kaijie Zhu, Wenxin Hou, Jianxun Lian, Fang Luo, Qiang
Yang, and Xing Xie. Large language models understand
and can be enhanced by emotional stimuli. arXiv preprint
arXiv:2307.11760, 2023.
[Li et al., 2023b] Chengshu Li, Jacky Liang, Andy Zeng,
Xinyun Chen, Karol Hausman, Dorsa Sadigh, Sergey
Levine, Li Fei-Fei, Fei Xia, and Brian Ichter. Chain of
code: Reasoning with a language model-augmented code
emulator. arXiv preprint arXiv:2312.04474, 2023.
[Li et al., 2023c] Jia Li, Ge Li, Yongmin Li, and Zhi Jin.
Structured chain-of-thought prompting for code generation.
arXiv preprint arXiv:2305.06599, 2023.
[Li et al., 2023d] Xingxuan Li, Ruochen Zhao, Yew Ken
Chia, Bosheng Ding, Shafiq Joty, Soujanya Poria, and Lidong Bing. Chain-of-knowledge: Grounding large language models via dynamic knowledge adapting over heterogeneous sources, 2023.
[Liu et al., 2023] Pengfei Liu, Weizhe Yuan, Jinlan Fu,
Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig.
Pre-train, prompt, and predict: A systematic survey of
prompting methods in natural language processing. ACM
Computing Surveys, 55(9):1–35, 2023.
[Long, 2023] Jieyi Long. Large language model guided treeof-thought. arXiv preprint arXiv:2305.08291, 2023.
[Nye et al., 2021] Maxwell Nye, Anders Johan Andreassen,
Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David
Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma,
David Luan, et al. Show your work: Scratchpads for intermediate computation with language models. arXiv preprint
arXiv:2112.00114, 2021.
[Paranjape et al., 2023] Bhargavi Paranjape, Scott Lundberg,
Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, and
Marco Tulio Ribeiro. Art: Automatic multi-step reasoning
and tool-use for large language models. arXiv preprint
arXiv:2303.09014, 2023.
[Radford et al., 2019] Alec Radford, Jeffrey Wu, Rewon
Child, David Luan, Dario Amodei, Ilya Sutskever, et al.
Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.
[Tonmoy et al., 2024] SM Tonmoy, SM Zaman, Vinija Jain,
Anku Rani, Vipula Rawte, Aman Chadha, and Amitava
Das. A comprehensive survey of hallucination mitigation techniques in large language models. arXiv preprint
arXiv:2401.01313, 2024.
