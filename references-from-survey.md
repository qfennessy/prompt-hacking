


# Organized Paper References

The main categories are:

- Foundational Language Model Papers
- Core Chain-of-Thought Methods
- Advanced Reasoning Patterns
- Tree-of-Thoughts and Graph Structures
- Task-Specific Adaptations
- Enhancement Techniques
- Verification and Reliability
- Knowledge Integration
- Prompting and Optimization
- Novel Approaches
- Special Applications

# Papers by Reasoning Pattern Taxonomy

## Foundational Language Model Papers
1. **Language Models are Unsupervised Multitask Learners (GPT-2)**
   - Authors: Alec Radford, et al.
   - Year: 2019
   - URL: https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf

2. **Language Models are Few-shot Learners (GPT-3)**
   - Authors: Tom B. Brown, et al.
   - Year: 2020
   - URL: https://arxiv.org/pdf/2005.14165

## Core Chain-of-Thought Methods

### Original Chain-of-Thought
1. **Chain-of-thought Prompting Elicits Reasoning in Large Language Models**
   - Authors: Jason Wei, et al.
   - Year: 2022
   - URL: https://arxiv.org/pdf/2201.11903

2. **Self-consistency Improves Chain of Thought Reasoning in Language Models**
   - Authors: Xuezhi Wang, et al.
   - Year: 2022
   - URL: https://arxiv.org/pdf/2203.11171

3. **Automatic Chain of Thought Prompting in Large Language Models**
   - Authors: Zhuosheng Zhang, et al.
   - Year: 2022
   - URL: https://arxiv.org/pdf/2210.03493

### Advanced Reasoning Patterns

#### Tree-of-Thoughts and Graph Structures
1. **Tree of Thoughts: Deliberate Problem Solving with Large Language Models**
   - Authors: Shunyu Yao, et al.
   - Year: 2023
   - URL: https://arxiv.org/pdf/2305.10601

2. **Large Language Model Guided Tree-of-thought**
   - Authors: Jieyi Long
   - Year: 2023
   - URL: https://arxiv.org/pdf/2305.08291

3. **Beyond Chain-of-thought, Effective Graph-of-thought Reasoning in Large Language Models**
   - Authors: Yao Yao, et al.
   - Year: 2023
   - URL: https://arxiv.org/pdf/2305.16582

#### Task-Specific Adaptations
1. **Chain-of-table: Evolving Tables in the Reasoning Chain for Table Understanding**
   - Authors: Zilong Wang, et al.
   - Year: 2024
   - URL: https://arxiv.org/pdf/2401.04398

2. **Chain of Code: Reasoning with a Language Model-augmented Code Emulator**
   - Authors: Chengshu Li, et al.
   - Year: 2023
   - URL: https://arxiv.org/pdf/2312.04474

3. **Structured Chain-of-thought Prompting for Code Generation**
   - Authors: Jia Li, et al.
   - Year: 2023
   - URL: https://arxiv.org/pdf/2305.06599

4. **Program of Thoughts Prompting: Disentangling Computation from Reasoning**
   - Authors: Wenhu Chen, et al.
   - Year: 2022
   - URL: https://arxiv.org/pdf/2211.12588

## Enhancement Techniques

### Verification and Reliability
1. **Chain-of-verification Reduces Hallucination in Large Language Models**
   - Authors: Shehzaad Dhuliawala, et al.
   - Year: 2023
   - URL: https://arxiv.org/pdf/2309.11495

2. **A Comprehensive Survey of Hallucination Mitigation Techniques**
   - Authors: SM Tonmoy, et al.
   - Year: 2024
   - URL: https://arxiv.org/pdf/2401.01313

### Knowledge Integration
1. **Chain-of-knowledge: Grounding Large Language Models via Dynamic Knowledge**
   - Authors: Xingxuan Li, et al.
   - Year: 2023
   - URL: https://arxiv.org/pdf/2305.13269

2. **Retrieval-augmented Generation for Knowledge-intensive NLP Tasks**
   - Authors: Patrick Lewis, et al.
   - Year: 2020
   - URL: https://arxiv.org/pdf/2005.11401

3. **Chain-of-note: Enhancing Robustness in Retrieval-augmented Language Models**
   - Authors: Wenhao Yu, et al.
   - Year: 2023
   - URL: https://arxiv.org/pdf/2311.09210

### Prompting and Optimization
1. **Large Language Models are Human-level Prompt Engineers**
   - Authors: Yongchao Zhou, et al.
   - Year: 2022
   - URL: https://arxiv.org/pdf/2211.01910

2. **Active Prompting with Chain-of-thought for Large Language Models**
   - Authors: Shizhe Diao, et al.
   - Year: 2023
   - URL: https://arxiv.org/pdf/2302.12246

3. **Large Language Models as Optimizers**
   - Authors: Chengrun Yang, et al.
   - Year: 2023
   - URL: https://arxiv.org/pdf/2309.03409

4. **Unleashing the Potential of Prompt Engineering in Large Language Models**
   - Authors: Banghao Chen, et al.
   - Year: 2023
   - URL: https://arxiv.org/pdf/2310.14735

### Novel Approaches
1. **System 2 Attention (Is Something You Might Need Too)**
   - Authors: Jason Weston, Sainbayar Sukhbaatar
   - Year: 2023
   - URL: https://arxiv.org/pdf/2311.11829

2. **Thread of Thought Unraveling Chaotic Contexts**
   - Authors: Yucheng Zhou, et al.
   - Year: 2023
   - URL: https://arxiv.org/pdf/2311.08734

3. **Chain-of-symbol Prompting Elicits Planning in Large Language Models**
   - Authors: Hanxu Hu, et al.
   - Year: 2023
   - URL: https://arxiv.org/pdf/2305.10276

4. **Contrastive Chain-of-thought Prompting**
   - Authors: Yew Ken Chia, et al.
   - Year: 2023
   - URL: https://arxiv.org/pdf/2311.09277

5. **Take a Step Back: Evoking Reasoning via Abstraction**
   - Authors: Huaixiu Steven Zheng, et al.
   - Year: 2023
   - URL: https://arxiv.org/pdf/2310.06117

6. **Show Your Work: Scratchpads for Intermediate Computation**
   - Authors: Maxwell Nye, et al.
   - Year: 2021
   - URL: https://arxiv.org/pdf/2112.00114

## Special Applications
1. **ReAct: Synergizing Reasoning and Acting in Language Models**
   - Authors: Shunyu Yao, et al.
   - Year: 2022
   - URL: https://arxiv.org/pdf/2210.03629

2. **Large Language Models Understand and Can Be Enhanced by Emotional Stimuli**
   - Authors: Cheng Li, et al.
   - Year: 2023
   - URL: https://arxiv.org/pdf/2307.11760

3. **Exploring Visual Prompts for Adapting Large-scale Models**
   - Authors: Hyojin Bahng, et al.
   - Year: 2022
   - URL: https://arxiv.org/pdf/2203.17274

## Prompt Examples

### Chain of Thought

Based on the paper, here are two examples of how to effectively prompt me (Claude) to use chain-of-thought reasoning:

####Example 1: Math Word Problem
"Please solve this problem step-by-step, showing your reasoning and calculations for each step:
At a restaurant, James ordered two appetizers costing $12 each and three main courses costing $24 each. The restaurant adds an 18% service charge. What was his total bill?"

This prompting encourages me to show reasoning like:
1. First, let me calculate the cost of appetizers: 2 appetizers × $12 = $24
2. Next, the main courses: 3 courses × $24 = $72
3. The subtotal before service charge is: $24 + $72 = $96
4. The 18% service charge would be: $96 × 0.18 = $17.28
5. Therefore, the total bill is: $96 + $17.28 = $113.28
The answer is $113.28.

####Example 2: Commonsense Reasoning
"Please explain your reasoning step by step:
Would a plant grow better in a basement or a sunroom?"

This prompting encourages me to show reasoning like:
1. Let me consider what plants need to grow: sunlight, water, appropriate temperature, and air
2. A sunroom is designed to let in natural light through many windows
3. A basement typically has little to no natural light
4. While both spaces can be temperature-controlled and watered
5. The crucial difference is sunlight access - most plants require sunlight for photosynthesis
Therefore, a plant would grow better in a sunroom.

####Key elements from the paper for effective chain-of-thought prompting:
- Explicitly request step-by-step reasoning
- Ask for intermediate steps to be shown
- Use phrases like "explain your reasoning" or "show your work"
- Encourage breaking down complex problems into smaller parts
- Ask for explanations that lead to the final answer


### Self-Consistency

# Using Self-Consistency with Claude

## Basic Structure

1. **Initial Request Format**
```
I need multiple different reasoning paths for this question. Please provide 3-5 different ways to think through it, then identify the most consistent answer:

[Your question here]
```

## Example Prompts

Here are specific prompt examples for each type of prompt. Each example is crafted to illustrate the unique properties and methodologies within each category.

---

## Core Chain-of-Thought Methods

### Original Chain-of-Thought

1. **Chain-of-thought Prompting Elicits Reasoning in Large Language Models**
   - **Prompt**: "Explain how you would determine the best travel route for a trip that includes three cities (City A, City B, and City C) considering travel time, cost, and available amenities. List each step in your reasoning and why it's important."

2. **Self-consistency Improves Chain of Thought Reasoning in Language Models**
   - **Prompt**: "Describe the steps you would take to solve the math problem: 'If there are 12 apples and you give 4 to each friend, how many friends can you give apples to?' Provide multiple approaches, and compare them to ensure consistency."

3. **Automatic Chain of Thought Prompting in Large Language Models**
   - **Prompt**: "Consider the problem: 'You need to schedule 5 meetings within a day, each lasting one hour, with a one-hour break in the middle. List the possible times for each meeting.' Outline your thought process step-by-step."

---

### Advanced Reasoning Patterns

#### Tree-of-Thoughts and Graph Structures

1. **Tree of Thoughts: Deliberate Problem Solving with Large Language Models**
   - **Prompt**: "To solve a complex problem like finding the best investment portfolio, break down the decision-making into a tree structure, considering different asset classes, risk levels, and time horizons at each branch."

2. **Large Language Model Guided Tree-of-Thought**
   - **Prompt**: "Generate a tree of thought for planning a healthy diet over a week. Start with meal types (breakfast, lunch, dinner) and branch out by food groups, nutritional needs, and daily variety."

3. **Beyond Chain-of-thought, Effective Graph-of-thought Reasoning in Large Language Models**
   - **Prompt**: "Use a graph structure to analyze a project with interconnected tasks. Each task should show dependencies, such as 'Task A must finish before Task B can start,' and provide reasoning for this arrangement."

---

## Task-Specific Adaptations

1. **Chain-of-table: Evolving Tables in the Reasoning Chain for Table Understanding**
   - **Prompt**: "You have a table showing daily temperature and precipitation levels for a month. Describe how you would analyze trends to predict if any patterns indicate a coming drought, adjusting your reasoning as new data points are added."

2. **Chain of Code: Reasoning with a Language Model-augmented Code Emulator**
   - **Prompt**: "Write a Python function to filter a list of numbers for only even numbers. Explain each line of code and reason about its efficiency and correctness."

3. **Structured Chain-of-thought Prompting for Code Generation**
   - **Prompt**: "Given a requirement to develop a function that sorts a list of names alphabetically, outline each part of the code with specific comments explaining the logic behind each step."

4. **Program of Thoughts Prompting: Disentangling Computation from Reasoning**
   - **Prompt**: "Solve the problem: 'Calculate the area of a circle with radius 5,' separating the computation steps from the reasoning about why each formula is used."

---

## Enhancement Techniques

### Verification and Reliability

1. **Chain-of-verification Reduces Hallucination in Large Language Models**
   - **Prompt**: "Explain why rainbows appear in the sky after rain. Verify each point by comparing it to known scientific principles about light, water droplets, and refraction."

2. **A Comprehensive Survey of Hallucination Mitigation Techniques**
   - **Prompt**: "Analyze the statement: 'Eating carrots improves eyesight.' Use a verification chain to assess the validity, citing known scientific studies or principles at each step."

### Knowledge Integration

1. **Chain-of-knowledge: Grounding Large Language Models via Dynamic Knowledge**
   - **Prompt**: "Explain the economic impact of inflation, integrating recent data from the Federal Reserve and historical inflation trends in your reasoning."

2. **Retrieval-augmented Generation for Knowledge-intensive NLP Tasks**
   - **Prompt**: "Describe the causes of the French Revolution, using specific historical data retrieved from reliable sources, and cite each source as you build your explanation."

3. **Chain-of-note: Enhancing Robustness in Retrieval-augmented Language Models**
   - **Prompt**: "Discuss the global impact of climate change, pulling from up-to-date reports and studies. Take notes on the key points and check the relevance of each note to the overall argument."

---

## Prompting and Optimization

1. **Large Language Models are Human-level Prompt Engineers**
   - **Prompt**: "Design a prompt to generate a story about a heroic dog rescuing a family. Adjust the prompt to elicit more vivid descriptions of the dog’s bravery and surroundings."

2. **Active Prompting with Chain-of-thought for Large Language Models**
   - **Prompt**: "When trying to solve the puzzle 'If you move one matchstick in a square made of four matches, how many triangles can you make?' guide the model to explore multiple potential matchstick moves and evaluate each outcome."

3. **Large Language Models as Optimizers**
   - **Prompt**: "Optimize a prompt to generate a business proposal for launching an eco-friendly product. Refine the prompt to emphasize cost-effectiveness, sustainability, and market potential in each section."

4. **Unleashing the Potential of Prompt Engineering in Large Language Models**
   - **Prompt**: "Create a prompt that will help generate a well-organized report on renewable energy adoption in urban areas, then refine it to improve focus on economic incentives and policy impacts."

---

## Novel Approaches

1. **System 2 Attention (Is Something You Might Need Too)**
   - **Prompt**: "Describe how System 2 attention would handle decision-making in a complex scenario, such as planning a city’s emergency response for a natural disaster, focusing on critical and sequential tasks."

2. **Thread of Thought Unraveling Chaotic Contexts**
   - **Prompt**: "Given an unstructured account of an event with conflicting witness statements, use a 'thread of thought' approach to unravel the sequence of events logically."

3. **Chain-of-symbol Prompting Elicits Planning in Large Language Models**
   - **Prompt**: "Create a plan for managing resources in a disaster relief effort using symbols to represent resources (e.g., food = F, water = W). Break down each action symbolically and explain its role."

4. **Contrastive Chain-of-thought Prompting**
   - **Prompt**: "Explain why certain animals are better suited to cold climates while others thrive in warmth. Use a contrasting approach to highlight adaptations in each type."

5. **Take a Step Back: Evoking Reasoning via Abstraction**
   - **Prompt**: "Evaluate the effectiveness of online education vs. in-person learning. Abstract the key features of each to highlight strengths and weaknesses in different learning environments."

6. **Show Your Work: Scratchpads for Intermediate Computation**
   - **Prompt**: "Calculate the solution to this problem step-by-step: 'If a train travels at 60 mph for 2 hours and then 40 mph for the next hour, what is the total distance traveled?' Show your intermediate steps."

---

## Special Applications

1. **ReAct: Synergizing Reasoning and Acting in Language Models**
   - **Prompt**: "Plan a project where an LLM needs to both make predictions about stock market trends and take actions to adjust a hypothetical portfolio based on those predictions. Describe each action step and the reasoning behind it."

2. **Large Language Models Understand and Can Be Enhanced by Emotional Stimuli**
   - **Prompt**: "Generate a motivational message for someone facing challenges in their career. Reflect empathy and encouragement, responding to the emotional aspects of career setbacks."

3. **Exploring Visual Prompts for Adapting Large-scale Models**
   - **Prompt**: "Explain how you would adapt a visual prompt for a model to recognize handwritten digits accurately. Describe how different visual styles and backgrounds might affect model interpretation."

---

These examples can be directly applied to understand and explore each specific prompt type in research or practical implementations.